version: v1.1

# Embedder configuration
embedder:
  provider: openai
  config:
    apiKey: ${OPENAI_API_KEY}
    model: text-embedding-3-small
    embeddingDims: 1536  # Optional: Specify embedding dimensions

# Vector store configuration
vectorStore:
  provider: memory  # Options: memory, qdrant, pinecone, chroma, etc.
  config:
    # Common parameters
    collectionName: memories      # Name of the collection to store vectors in
    dimension: 1536              # Dimensions of the vectors (for memory provider)
    embeddingModelDims: 1536     # Dimensions of the embedding model (should match your embedder)

    # Connection parameters (uncomment and configure based on your vector DB provider)

    # Server connection (for Qdrant, Pinecone, etc.)
    # host: localhost            # Host where the vector database server is running
    # port: 6333                 # Port where the vector database server is running
    # url: https://your-vector-db-url  # URL for the vector database server (alternative to host/port)
    # apiKey: your-api-key       # API key for authenticated vector database services

    # File-based storage
    # path: ./vector-db          # Path for file-based vector databases
    # onDisk: true               # Enable persistent storage (for memory provider)

    # Redis connection (for Redis-based vector stores)
    # redisUrl: redis://localhost:6379  # URL for the Redis server

    # Authentication (for databases requiring authentication)
    # username: user             # Username for database connection
    # password: pass             # Password for database connection

# LLM configuration
llm:
  provider: openai  # Options: openai, anthropic, etc.
  config:
    apiKey: ${OPENAI_API_KEY}
    model: gpt-4-turbo-preview
    temperature: 0.7  # Optional: Control randomness (0.0 to 1.0)
    maxTokens: 1000   # Optional: Maximum tokens to generate
    # topP: 0.9       # Optional: Nucleus sampling parameter
    # topK: 40        # Optional: Top-k sampling parameter
    # openaiBaseUrl: https://your-openai-proxy  # Optional: Custom OpenAI API endpoint

# History store configuration
historyDbPath: memory.db  # Path to SQLite database for memory history

# Optional: Use Supabase for history in serverless environments
# historyStore:
#   provider: supabase
#   config:
#     supabaseUrl: ${SUPABASE_URL}
#     supabaseKey: ${SUPABASE_KEY}
#     tableName: memory_history

# Optional: Disable history tracking
# disableHistory: false
